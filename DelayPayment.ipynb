{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Fk_Produit  Fk_Invoices  Fk_Supplier  Fk_Date  Fk_Geographie  \\\n",
      "0         996         7256          243     8776             78   \n",
      "1         760         3624          183    10456             18   \n",
      "2         771         6001          189     8929             24   \n",
      "3         871          552          219     9008             54   \n",
      "4         981          638          240     9721             75   \n",
      "\n",
      "   Fk_InvoiceDate  Fk_DueDate  Fk_PaymentDate  Price   Amount  \\\n",
      "0            8474        9291            8776    3.0  4133.94   \n",
      "1            9166        8729           10456    2.5  3941.63   \n",
      "2            8674        8775            8929    1.8  3081.99   \n",
      "3            9628        9331            9008   22.0   820.28   \n",
      "4            9230        9312            9721    7.0  1836.40   \n",
      "\n",
      "   DiscountOffered  RecommendedProfitMargin PaymentDate     DueDate  \n",
      "0           488.75                     45.0  2021-01-11  2022-06-10  \n",
      "1            88.94                     40.0  2025-08-18  2020-11-25  \n",
      "2           144.04                     45.0  2021-06-13  2021-01-10  \n",
      "3            71.79                     45.0  2021-08-31  2022-07-20  \n",
      "4           170.50                     45.0  2023-08-14  2022-07-01  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_25996\\516452031.py:47: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql_query, conn)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "\n",
    "# Connection details — update as needed\n",
    "server = 'DESKTOP-I9NMGNC'       # e.g. 'localhost\\\\SQLEXPRESS'\n",
    "database = 'DW_Finance'\n",
    "username = 'amin'\n",
    "password = 'amin'\n",
    "\n",
    "# Create the connection string\n",
    "conn_str = (\n",
    "    f'DRIVER={{ODBC Driver 17 for SQL Server}};'\n",
    "    f'SERVER={server};'\n",
    "    f'DATABASE={database};'\n",
    "    f'UID={username};'\n",
    "    f'PWD={password}'\n",
    ")\n",
    "\n",
    "# Establish the connection\n",
    "conn = pyodbc.connect(conn_str)\n",
    "\n",
    "# Define the SQL query\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "    f.Fk_Produit,\n",
    "    f.Fk_Invoices,\n",
    "    f.Fk_Supplier,\n",
    "    f.Fk_Date,\n",
    "    f.Fk_Geographie,\n",
    "    f.Fk_InvoiceDate,\n",
    "    f.Fk_DueDate,\n",
    "    f.Fk_PaymentDate,\n",
    "    f.Price,\n",
    "    f.Amount,\n",
    "    f.DiscountOffered,\n",
    "    f.RecommendedProfitMargin,\n",
    "    d.PaymentDate,  -- from Dim_Supplier\n",
    "    d.DueDate       -- from Dim_Supplier\n",
    "FROM \n",
    "    DW_Finance.dbo.Fact_Purchase f\n",
    "JOIN \n",
    "    DW_Finance.dbo.Dim_Supplier d\n",
    "    ON f.Fk_Supplier = d.Pk_Supplier\n",
    "\"\"\"\n",
    "\n",
    "# Run the query and load into DataFrame\n",
    "df = pd.read_sql(sql_query, conn)\n",
    "\n",
    "# Show the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PaymentDate     DueDate  LatePayment\n",
      "0  2021-01-11  2022-06-10            0\n",
      "1  2025-08-18  2020-11-25            1\n",
      "2  2021-06-13  2021-01-10            1\n",
      "3  2021-08-31  2022-07-20            0\n",
      "4  2023-08-14  2022-07-01            1\n"
     ]
    }
   ],
   "source": [
    "# Create the LatePayment column: 1 if payment is late, 0 if on time\n",
    "df['LatePayment'] = (df['PaymentDate'] > df['DueDate']).astype(int)\n",
    "\n",
    "# Display the updated data with the new column\n",
    "print(df[['PaymentDate', 'DueDate', 'LatePayment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Price   Amount  DiscountOffered  RecommendedProfitMargin\n",
      "0    3.0  4133.94           488.75                     45.0\n",
      "1    2.5  3941.63            88.94                     40.0\n",
      "2    1.8  3081.99           144.04                     45.0\n",
      "3   22.0   820.28            71.79                     45.0\n",
      "4    7.0  1836.40           170.50                     45.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define features (X,y)\n",
    "X = df[['Price', 'Amount', 'DiscountOffered', 'RecommendedProfitMargin']]\n",
    "y = df['LatePayment']\n",
    "\n",
    "\n",
    "# Inspect the features\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[30 16]\n",
      " [14 56]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.67        46\n",
      "           1       0.78      0.80      0.79        70\n",
      "\n",
      "    accuracy                           0.74       116\n",
      "   macro avg       0.73      0.73      0.73       116\n",
      "weighted avg       0.74      0.74      0.74       116\n",
      "\n",
      "Accuracy: 0.7413793103448276\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.2}\n",
      "\n",
      "Confusion Matrix:\n",
      " [[32 14]\n",
      " [16 54]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.68        46\n",
      "           1       0.79      0.77      0.78        70\n",
      "\n",
      "    accuracy                           0.74       116\n",
      "   macro avg       0.73      0.73      0.73       116\n",
      "weighted avg       0.74      0.74      0.74       116\n",
      "\n",
      "Accuracy: 0.7413793103448276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Class imbalance handling\n",
    "scale_pos_weight = 230 / 348  # ≈ 0.66\n",
    "\n",
    "# Simplified parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 1.0],\n",
    "}\n",
    "\n",
    "# Base model with scale_pos_weight\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "\n",
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Predict\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[39  7]\n",
      " [20 50]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.85      0.74        46\n",
      "           1       0.88      0.71      0.79        70\n",
      "\n",
      "    accuracy                           0.77       116\n",
      "   macro avg       0.77      0.78      0.77       116\n",
      "weighted avg       0.79      0.77      0.77       116\n",
      "\n",
      "Accuracy: 0.7672413793103449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python313\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [21:06:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Prepare the data in DMatrix format (required by xgb.train)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Define the parameter grid\n",
    "params = {\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 300,\n",
    "    'subsample': 1.0,\n",
    "    'scale_pos_weight': 230 / 348,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "# Define evaluation set for early stopping\n",
    "evals = [(dtrain, 'train'), (dtest, 'test')]\n",
    "\n",
    "# Train the model using xgb.train (with early stopping)\n",
    "model1 = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=300,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=10,\n",
    "    verbose_eval=False  # Disable log output\n",
    ")\n",
    "\n",
    "# Get the best iteration (early stopping should help stop training early)\n",
    "best_iteration = model.best_iteration\n",
    "\n",
    "# Predict using the best iteration with iteration_range\n",
    "y_pred = model1.predict(dtest, iteration_range=(0, best_iteration))\n",
    "y_pred = (y_pred > 0.5).astype(int)  # Assuming binary classification\n",
    "\n",
    "# Evaluation metrics\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning Rate: 0.01\n",
      "Confusion Matrix:\n",
      " [[40  6]\n",
      " [17 53]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78        46\n",
      "           1       0.90      0.76      0.82        70\n",
      "\n",
      "    accuracy                           0.80       116\n",
      "   macro avg       0.80      0.81      0.80       116\n",
      "weighted avg       0.82      0.80      0.80       116\n",
      "\n",
      "Accuracy: 0.8017241379310345\n",
      "\n",
      "Learning Rate: 0.05\n",
      "Confusion Matrix:\n",
      " [[40  6]\n",
      " [18 52]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77        46\n",
      "           1       0.90      0.74      0.81        70\n",
      "\n",
      "    accuracy                           0.79       116\n",
      "   macro avg       0.79      0.81      0.79       116\n",
      "weighted avg       0.81      0.79      0.80       116\n",
      "\n",
      "Accuracy: 0.7931034482758621\n",
      "\n",
      "Learning Rate: 0.1\n",
      "Confusion Matrix:\n",
      " [[35 11]\n",
      " [16 54]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        46\n",
      "           1       0.83      0.77      0.80        70\n",
      "\n",
      "    accuracy                           0.77       116\n",
      "   macro avg       0.76      0.77      0.76       116\n",
      "weighted avg       0.77      0.77      0.77       116\n",
      "\n",
      "Accuracy: 0.7672413793103449\n",
      "\n",
      "Learning Rate: 0.2\n",
      "Confusion Matrix:\n",
      " [[40  6]\n",
      " [18 52]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77        46\n",
      "           1       0.90      0.74      0.81        70\n",
      "\n",
      "    accuracy                           0.79       116\n",
      "   macro avg       0.79      0.81      0.79       116\n",
      "weighted avg       0.81      0.79      0.80       116\n",
      "\n",
      "Accuracy: 0.7931034482758621\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Prepare the data in DMatrix format (required by xgb.train)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Define the parameter grid for different learning rates\n",
    "learning_rates = [0.01, 0.05, 0.1, 0.2]\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate the model for each learning rate\n",
    "for lr in learning_rates:\n",
    "    # Define the parameter grid\n",
    "    params = {\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': lr,\n",
    "        'subsample': 1.0,\n",
    "        'scale_pos_weight': 230 / 348,\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "\n",
    "    # Define evaluation set for early stopping\n",
    "    evals = [(dtrain, 'train'), (dtest, 'test')]\n",
    "\n",
    "    # Train the model using xgb.train (with early stopping)\n",
    "    model = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=300,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=False  # Disable log output\n",
    "    )\n",
    "\n",
    "    # Get the best iteration (early stopping should help stop training early)\n",
    "    best_iteration = model.best_iteration\n",
    "\n",
    "    # Predict using the best iteration with iteration_range\n",
    "    y_pred = model.predict(dtest, iteration_range=(0, best_iteration))\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # Assuming binary classification\n",
    "\n",
    "    # Evaluate the model\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Store results for this learning rate\n",
    "    results[lr] = {\n",
    "        'Confusion Matrix': conf_matrix,\n",
    "        'Classification Report': class_report,\n",
    "        'Accuracy': accuracy\n",
    "    }\n",
    "\n",
    "# Print results for all learning rates\n",
    "for lr, result in results.items():\n",
    "    print(f\"\\nLearning Rate: {lr}\")\n",
    "    print(\"Confusion Matrix:\\n\", result['Confusion Matrix'])\n",
    "    print(\"\\nClassification Report:\\n\", result['Classification Report'])\n",
    "    print(\"Accuracy:\", result['Accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning Rate: 0.01\n",
      "Confusion Matrix:\n",
      " [[40  6]\n",
      " [17 53]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78        46\n",
      "           1       0.90      0.76      0.82        70\n",
      "\n",
      "    accuracy                           0.80       116\n",
      "   macro avg       0.80      0.81      0.80       116\n",
      "weighted avg       0.82      0.80      0.80       116\n",
      "\n",
      "Accuracy: 0.8017241379310345\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Prepare the data in DMatrix format (required by xgb.train)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Define the learning rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Define the parameter grid\n",
    "params = {\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': learning_rate,\n",
    "    'subsample': 1.0,\n",
    "    'scale_pos_weight': 230 / 348,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "# Define evaluation set for early stopping\n",
    "evals = [(dtrain, 'train'), (dtest, 'test')]\n",
    "\n",
    "# Train the model using xgb.train (with early stopping)\n",
    "final_model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=300,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=10,\n",
    "    verbose_eval=False  # Disable log output\n",
    ")\n",
    "\n",
    "# Get the best iteration (early stopping should help stop training early)\n",
    "best_iteration = model.best_iteration\n",
    "\n",
    "# Predict using the best iteration with iteration_range\n",
    "y_pred = final_model.predict(dtest, iteration_range=(0, best_iteration))\n",
    "y_pred = (y_pred > 0.5).astype(int)  # Assuming binary classification\n",
    "\n",
    "# Evaluate the model\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\nLearning Rate: {learning_rate}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data from Own Dataset:\n",
      "     Price   Amount  DiscountOffered  RecommendedProfitMargin\n",
      "40     3.0   507.49           428.14                     45.0\n",
      "109   15.0   858.81           420.02                     45.0\n",
      "510    2.0  3283.41           410.80                     45.0\n",
      "268    8.0  3916.15           429.72                     45.0\n",
      "351   60.0  3348.28           132.02                     45.0\n",
      "76     3.0   323.27           245.11                     45.0\n",
      "84     8.5  2224.45           403.62                     45.0\n",
      "3     22.0   820.28            71.79                     45.0\n",
      "111    3.8  1728.51            13.58                     45.0\n",
      "566    4.5  2751.92           176.78                     45.0\n",
      "\n",
      "Predictions for Own Dataset Samples: [1 0 0 1 1 0 1 0 1 0]\n",
      "Sample 1: Predicted = 1, Actual = 1 - Correct\n",
      "Sample 2: Predicted = 0, Actual = 0 - Correct\n",
      "Sample 3: Predicted = 0, Actual = 1 - Wrong\n",
      "Sample 4: Predicted = 1, Actual = 1 - Correct\n",
      "Sample 5: Predicted = 1, Actual = 1 - Correct\n",
      "Sample 6: Predicted = 0, Actual = 0 - Correct\n",
      "Sample 7: Predicted = 1, Actual = 1 - Correct\n",
      "Sample 8: Predicted = 0, Actual = 0 - Correct\n",
      "Sample 9: Predicted = 1, Actual = 1 - Correct\n",
      "Sample 10: Predicted = 0, Actual = 0 - Correct\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming X is your feature dataframe and y is the target dataframe\n",
    "\n",
    "# Get 3 random samples from your own dataset (X)\n",
    "sample_data_own = X.sample(10)  # Adjust the number of samples as needed\n",
    "\n",
    "# Display the sample data\n",
    "print(\"Sample Data from Own Dataset:\")\n",
    "print(sample_data_own)\n",
    "\n",
    "# Convert to DMatrix format for XGBoost model prediction\n",
    "sample_data_own_dmatrix = xgb.DMatrix(sample_data_own)\n",
    "\n",
    "# Predict on your own data samples\n",
    "sample_own_predictions = final_model.predict(sample_data_own_dmatrix)\n",
    "\n",
    "# Convert predictions to binary (0 or 1)\n",
    "sample_own_predictions_binary = (sample_own_predictions > 0.5).astype(int)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"\\nPredictions for Own Dataset Samples:\", sample_own_predictions_binary)\n",
    "\n",
    "# Get the actual labels for the selected samples\n",
    "sample_labels = y[sample_data_own.index]\n",
    "\n",
    "# Compare predictions with actual labels and print results\n",
    "for i, (pred, actual) in enumerate(zip(sample_own_predictions_binary, sample_labels)):\n",
    "    result = \"Correct\" if pred == actual else \"Wrong\"\n",
    "    print(f\"Sample {i+1}: Predicted = {pred}, Actual = {actual} - {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Price  Amount  DiscountOffered  RecommendedProfitMargin\n",
      "0      7       1                0                       90\n",
      "1   9999   50000              999                        0\n",
      "2    350     320                8                       25\n",
      "3     42    8888              123                        5\n",
      "4     10     200               77                       60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Highly varied and random external data samples\n",
    "external_samples = pd.DataFrame({\n",
    "    'Price': [7, 9999, 350, 42, 10],\n",
    "    'Amount': [1, 50000, 320, 8888, 200],\n",
    "    'DiscountOffered': [0, 999, 8, 123, 77],\n",
    "    'RecommendedProfitMargin': [90, 0, 25, 5, 60]\n",
    "})\n",
    "\n",
    "# Display the sample data\n",
    "print(external_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for external samples: [1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert to DMatrix format (for XGBoost model)\n",
    "external_samples_dmatrix = xgb.DMatrix(external_samples)\n",
    "\n",
    "# Predict on the external data samples\n",
    "external_predictions = final_model.predict(external_samples_dmatrix)\n",
    "\n",
    "# Convert the predictions to binary (0 or 1)\n",
    "external_predictions_binary = (external_predictions > 0.5).astype(int)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions for external samples:\", external_predictions_binary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
